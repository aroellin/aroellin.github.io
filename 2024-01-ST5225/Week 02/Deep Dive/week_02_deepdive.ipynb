{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ST5225 Statistical Analysis of Networks — Deep Dive\n",
    "# Week 2 — Basic Quantities and Properties of Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This session's network: Instagram\n",
    "This is an Instagram social network data for Influence Maximization (IM) task. It was collected from Instagram on April to May 2020, from the followers of 24 private universities in Malaysia, using Instagram API and various third-party Instagram websites. It consists of mostly Malaysian users, with 70,409 nodes/users, 1,007,107 edges/connections (followees and followers).\n",
    "Download \"Network for IC LT.txt\" from [Kaggle](https://www.kaggle.com/datasets/krpurba/im-instagram-70k). You need to register to download the file.\n",
    "The CSV file contains three values in each row: Source (\"follower\"), Target (\"followee\"), and a weight, which we can ignore. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the file into a dataframe\n",
    "df = pd.read_csv('Network for IC LT.txt', sep=' ', skiprows=1, header=None)\n",
    "\n",
    "# Display the dataframe\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a directed graph from the dataframe\n",
    "G = nx.from_pandas_edgelist(df, source=0, target=1, create_using=nx.DiGraph())\n",
    "\n",
    "# Print the graph\n",
    "print(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Extract the top nodes with the highest in-degrees\n",
    "top_nodes = sorted(G.in_degree(), key=lambda x: x[1], reverse=True)[:50]\n",
    "\n",
    "# Create a subgraph with the top nodes\n",
    "subgraph = G.subgraph([node for node, _ in top_nodes])\n",
    "\n",
    "# Use spring layout\n",
    "pos = nx.kamada_kawai_layout(subgraph)\n",
    "\n",
    "# Calculate node sizes based on the square root of the in-degree\n",
    "node_sizes = [np.sqrt(subgraph.in_degree(node)) * 100 for node in subgraph]  # Adjust the multiplier as needed for visualization\n",
    "\n",
    "# Visualize the subgraph with node sizes proportional to the square root of the in-degree\n",
    "nx.draw(subgraph, pos, with_labels=False, node_size=node_sizes)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Degrees\n",
    "\n",
    "We first calculate the degree distribtion of this directed graph. We can calculate three types of degrees: in-degree, out-degree, and total degree. The in-degree of a node is the number of edges coming into the node, the out-degree of a node is the number of edges going out of the node, and the total degree of a node is the sum of the in-degree and out-degree of the node.\n",
    "\n",
    "For this dataset, we will focus on the in-degrees (\"number of followers\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "powershell"
    }
   },
   "outputs": [],
   "source": [
    "degrees = G.in_degree()\n",
    "print(degrees)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's sort this data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "powershell"
    }
   },
   "outputs": [],
   "source": [
    "degree_seq = sorted((d for n, d in degrees), reverse=True)\n",
    "print(degree_seq[:20])\n",
    "print(degree_seq[-20:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now calculate the degree distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# Create a Counter object for the in_degree_seq list\n",
    "degree_counter = Counter(degree_seq)\n",
    "\n",
    "degree_dist = pd.DataFrame.from_dict(degree_counter, orient='index', columns=['Frequency'])\n",
    "degree_dist.index.name = 'Degree'\n",
    "degree_dist.reset_index(inplace=True)\n",
    "degree_dist = degree_dist[degree_dist['Degree'] != 0]\n",
    "\n",
    "print(degree_dist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot this distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(degree_dist['Degree'], degree_dist['Frequency'], s=2)\n",
    "plt.xlabel('Degree')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Degree Distribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is not very useful. Let's plot this on the log-log scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.loglog(degree_dist['Degree'], degree_dist['Frequency'], marker='o', linestyle='None', markersize=2)\n",
    "plt.xlabel('Degree')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Degree Distribution (Log-Log Scale)')\n",
    "plt.ylim([1, 10000])  # Set the y-axis range from 1 to 1000\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Filter out the data points with degree less than 10 \n",
    "high_degree_dist = degree_dist[degree_dist['Degree'] >= 10]\n",
    "\n",
    "# Convert the degree and frequency data to numpy arrays\n",
    "degree = np.array(high_degree_dist['Degree'])\n",
    "frequency = np.array(high_degree_dist['Frequency'])\n",
    "\n",
    "# Take the logarithm of the degree and frequency arrays\n",
    "log_degree = np.log(degree)\n",
    "log_frequency = np.log(frequency)\n",
    "\n",
    "# Perform the linear regression using numpy's polyfit function\n",
    "slope, intercept = np.polyfit(log_degree, log_frequency, 1)\n",
    "\n",
    "# Print the equation of the linear regression line\n",
    "print(f\"Log(Frequency) = {intercept:.4f} + {slope:.4f} * Log(Degree)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.loglog(degree_dist['Degree'], degree_dist['Frequency'], marker='o', linestyle='None', markersize=2)\n",
    "plt.plot(degree_dist['Degree'], np.exp(intercept) * degree_dist['Degree'] ** slope, color='red', label='Fit Line')  \n",
    "\n",
    "\n",
    "plt.xlabel('Degree')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Degree Distribution (Log-Log Scale)')\n",
    "plt.ylim([1, 10000])  # Set the y-axis range from 1 to 1000\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many network scientists (especially those from the physics community) get excited when they see a straight line on a log-log plot of the degree distribution, as this implies a \"power law distribution\": $$d(k) = k^{-\\alpha},$$ where $d(k)$ is the number of nodes of degree k and $\\alpha>1$. We will encouter this phenomenon when studying preferential attachement random graphs (the \"rich-get-richer phenomenon\").\n",
    "\n",
    " However, there has been much debate recently about when a straight line is really a straight line, since on a log-log plot, many distributions look like a straight line. Our Instragram data seems not to exhibit a straight line, which is sort of surprising, since social network data is exactly the kind of data where one would expect to see a powerlaw. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Edge density\n",
    "\n",
    "We now calculate the edge density. For undirected graph, the edge density is defined to be $$\\frac{2 e}{n(n-1)},$$ where $e$ is the number of undirected edges and $n$ the number of vertices. For directed graphs, the edge density is defined to be $$\\frac{e}{n(n-1)},$$ where $e$ is the number of directed edges. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Edge Density:\", nx.density(G))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is this sparse or dense? A better indicator is the average degree:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming your directed graph is stored in the variable G\n",
    "in_degrees = dict(G.in_degree())\n",
    "out_degrees = dict(G.out_degree())\n",
    "\n",
    "# Calculate average in-degree\n",
    "avg_in_degree = sum(in_degrees.values()) / len(in_degrees)\n",
    "\n",
    "# Calculate average out-degree\n",
    "avg_out_degree = sum(out_degrees.values()) / len(out_degrees)\n",
    "\n",
    "print(\"Average In-Degree:\", avg_in_degree)\n",
    "print(\"Average Out-Degree:\", avg_out_degree)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The average in- and out-degrees must equal each other (why?). The value above is moderate, so one could argue this is a sparse graph. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Betweeness centrality\n",
    "\n",
    "Let us now calculate the betweeness centrality of the vertices in the Instagramm network. Recall that the betweenness centrality of a vertex $v$ is calculated as the sum of the fractions of shortest paths between all pairs of vertices that pass through $v$. This value is actually computationally expensive, so we resort to a \"Monte Carlo\" approach, which means, we take random samples and estimate the values. Since $G$ is a directed graph, the paths considered are the directed paths only.\n",
    "\n",
    "Let's continue with only those edges with large in-degree (\"influencers\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_hi = nx.Graph(G.subgraph([node for node, degree in G.degree() if degree >= 100]))\n",
    "\n",
    "print(G_hi)\n",
    "\n",
    "# Calculate the betweenness centrality of the nodes in the graph; k is the number of samples to use, since calculating the true values is computationally expensive\n",
    "betweenness_centrality = nx.betweenness_centrality(G_hi, k=300)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_top_vertices = 50\n",
    "\n",
    "top_vertices_b = sorted(betweenness_centrality.items(), key=lambda x: x[1], reverse=True)[:num_top_vertices]\n",
    "\n",
    "for vertex in top_vertices_b[:10]:\n",
    "  print(f\"Vertex: {vertex[0]}, Centrality: {vertex[1]}\")\n",
    "\n",
    "# Create a subgraph with the top vertices\n",
    "subgraph_b = nx.DiGraph(G_hi.subgraph([vertex[0] for vertex in top_vertices_b]))\n",
    "subgraph_b.remove_nodes_from(list(nx.isolates(subgraph)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use spring layout\n",
    "pos = nx.kamada_kawai_layout(subgraph_b)\n",
    "\n",
    "# Calculate node sizes based on the square root of the in-degree\n",
    "node_sizes = [np.sqrt(subgraph_b.in_degree(node)) * 100 for node in subgraph_b]  # Adjust the multiplier as needed for visualization\n",
    "\n",
    "# Visualize the subgraph with node sizes proportional to the square root of the in-degree\n",
    "nx.draw(subgraph_b, pos, with_labels=False, node_size=node_sizes)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Closeness centrality\n",
    "\n",
    "Let us now calculate the closeness centrality of the vertices in the Instagram network. Recall that the closeness centrality of a vertex $v$ is calculated as the reciprocal of the average shortest path length from $v$ to all other vertices. These values can be computed using *Dijkstra's algorithm*; see e.g. [Computing Classic Closeness Centrality, at Scale](https://www.microsoft.com/en-us/research/wp-content/uploads/2014/08/sabidussi_TR.pdf). The algorithm is exact, hence takes a few minutes to complete. It scales roughly like $\\Theta(n^2)$, where $n$ is number of vertices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the betweenness centrality of the nodes in the graph; k is the number of samples to use, since calculating the true values is computationally expensive\n",
    "closeness_centrality = nx.closeness_centrality(G_hi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_top_vertices = 50\n",
    "\n",
    "top_vertices_c = sorted(closeness_centrality.items(), key=lambda x: x[1], reverse=True)[:num_top_vertices]\n",
    "\n",
    "for vertex in top_vertices_c[:10]:\n",
    "  print(f\"Vertex: {vertex[0]}, Centrality: {vertex[1]}\")\n",
    "\n",
    "# Create a subgraph with the top vertices\n",
    "subgraph_c = nx.DiGraph(G.subgraph([vertex[0] for vertex in top_vertices_c]))\n",
    "subgraph_c.remove_nodes_from(list(nx.isolates(subgraph_c)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use spring layout\n",
    "pos = nx.kamada_kawai_layout(subgraph_c)\n",
    "\n",
    "# Calculate node sizes based on the square root of the in-degree\n",
    "node_sizes = [np.sqrt(subgraph_c.in_degree(node)) * 100 for node in subgraph_c]  # Adjust the multiplier as needed for visualization\n",
    "\n",
    "# Visualize the subgraph with node sizes proportional to the square root of the in-degree\n",
    "nx.draw(subgraph_c, pos, with_labels=False, node_size=node_sizes)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eigenvector centrality\n",
    "\n",
    "Let us now calculate the eigenvector centrality of the vertices in the Instagram network. Recall that the eigenvector centrality of a vertex $v$ is calculated by means of the adjacency matrix. Such methods are also called \"spectral methods\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the eigenvalue centrality of the nodes in the graph\n",
    "eigenvalue_centrality = nx.eigenvector_centrality(G_hi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_top_vertices = 50\n",
    "\n",
    "top_vertices_e = sorted(eigenvalue_centrality.items(), key=lambda x: x[1], reverse=True)[:num_top_vertices]\n",
    "\n",
    "for vertex in top_vertices_e[:10]:\n",
    "  print(f\"Vertex: {vertex[0]}, Centrality: {vertex[1]}\")\n",
    "\n",
    "# Create a subgraph with the top vertices\n",
    "subgraph_e = nx.DiGraph(G.subgraph([vertex[0] for vertex in top_vertices_e]))\n",
    "subgraph_e.remove_nodes_from(list(nx.isolates(subgraph_e)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use spring layout\n",
    "pos = nx.kamada_kawai_layout(subgraph_e)\n",
    "\n",
    "# Calculate node sizes based on the square root of the in-degree\n",
    "node_sizes = [np.sqrt(subgraph_e.in_degree(node)) * 100 for node in subgraph_e]  # Adjust the multiplier as needed for visualization\n",
    "\n",
    "# Visualize the subgraph with node sizes proportional to the square root of the in-degree\n",
    "nx.draw(subgraph_e, pos, with_labels=False, node_size=node_sizes)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Triangles and Cluster Coefficient\n",
    "\n",
    "We now calculate the triangles in the graph. To simplify things, we convert the graph into an undirected graph. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = G.to_undirected()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming G is your graph\n",
    "triangles = nx.triangles(G)\n",
    "\n",
    "# Calculate the total number of triangles\n",
    "num_triangles = sum(triangles.values()) // 3\n",
    "\n",
    "print(\"Number of triangles in G:\", num_triangles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us now calculate the number of 2-paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the number of two-paths using degree information\n",
    "num_two_paths = sum([degree * (degree - 1) // 2 for node, degree in G.degree()])\n",
    "print(\"Number of two-paths in G:\", num_two_paths)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now calculate the cluster coefficient as in our lecture: $$C = \\frac{3\\times\\text{number of triangles}}{\\text{number of 2-stars}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the clustering coefficient\n",
    "cluster_coefficient = 3 * num_triangles / num_two_paths\n",
    "\n",
    "print(f\"Cluster Coefficient: {cluster_coefficient}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In NetworkX, this can be calculated using the nx.transitivity function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Transitivity:\", nx.transitivity(G))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is also possible to calculate the cluster coefficient for each vertex individually: $$C_v = \\frac{3\\times\\text{number of triangles going through $v$}}{\\text{number of 2-stars with $v$ as centre}}.$$ This leads to the average cluster coefficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_coefficient = nx.average_clustering(G)\n",
    "print(\"Average Cluster Coefficient:\", cluster_coefficient)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Are these coefficients larger than one would expect? Need a null-model against which to test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rewire the graph G\n",
    "degrees = [degree for node, degree in G.degree()]\n",
    "rewired_G = nx.configuration_model(degrees)\n",
    "\n",
    "# Convert the rewired graph to a simple graph\n",
    "rewired_G = nx.Graph(rewired_G)\n",
    "\n",
    "# Assuming G is your graph\n",
    "num_triangles = sum(nx.triangles(rewired_G).values()) // 3\n",
    "num_two_paths = sum([degree * (degree - 1) // 2 for node, degree in rewired_G.degree()])\n",
    "\n",
    "# Calculate the clustering coefficient\n",
    "cluster_coefficient = 3 * num_triangles / num_two_paths\n",
    "\n",
    "print(f\"Cluster Coefficient: {cluster_coefficient}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Going by the simulation, the cluster coefficients of $G$ is larger than one would expect in a \"randomly chosen graph with the same degree sequence\" (configuration random graph model). That is, there are more triangles than one would expect. This is typical for social networks.  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ST5225",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
